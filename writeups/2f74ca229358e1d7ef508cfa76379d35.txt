1:"$Sreact.fragment"
2:I[87555,[],""]
3:I[31295,[],""]
4:I[6874,["874","static/chunks/874-3e820bd666038662.js","633","static/chunks/app/writeups/%5Bid%5D/layout-2577bd3482649595.js"],""]
6:I[59665,[],"OutletBoundary"]
8:I[74911,[],"AsyncMetadataOutlet"]
a:I[59665,[],"ViewportBoundary"]
c:I[59665,[],"MetadataBoundary"]
d:"$Sreact.suspense"
f:I[28393,[],""]
:HL["/_next/static/media/e4af272ccee01ff0-s.p.woff2","font",{"crossOrigin":"","type":"font/woff2"}]
:HL["/_next/static/css/154fc5c9afe7044c.css","style"]
0:{"P":null,"b":"_H-kM0bxtUnUwrwh28WmS","p":"","c":["","writeups","2f74ca229358e1d7ef508cfa76379d35"],"i":false,"f":[[["",{"children":["writeups",{"children":[["id","2f74ca229358e1d7ef508cfa76379d35","d"],{"children":["__PAGE__",{}]}]}]},"$undefined","$undefined",true],["",["$","$1","c",{"children":[[["$","link","0",{"rel":"stylesheet","href":"/_next/static/css/154fc5c9afe7044c.css","precedence":"next","crossOrigin":"$undefined","nonce":"$undefined"}]],["$","html",null,{"className":"dark scroll-smooth","children":[["$","head",null,{"children":["$","meta",null,{"charSet":"utf-8"}]}],["$","body",null,{"className":"text-dark dark:text-white dark:bg-midnight","style":{"fontFamily":"'Inter', 'Inter Fallback'","fontStyle":"normal"},"children":["$","$L2",null,{"parallelRouterKey":"children","error":"$undefined","errorStyles":"$undefined","errorScripts":"$undefined","template":["$","$L3",null,{}],"templateStyles":"$undefined","templateScripts":"$undefined","notFound":[["$","div",null,{"className":"h-screen flex items-center justify-center","children":["$","main",null,{"className":"relative pl-14","children":[["$","svg",null,{"stroke":"currentColor","fill":"currentColor","strokeWidth":"0","viewBox":"0 0 512 512","className":"absolute left-0 top-2 text-5xl text-grapefruit","children":["$undefined",[["$","path","0",{"d":"M256 48C140.559 48 48 140.559 48 256c0 115.436 92.559 208 208 208 115.435 0 208-92.564 208-208 0-115.441-92.564-208-208-208zm104.002 282.881l-29.12 29.117L256 285.117l-74.881 74.881-29.121-29.117L226.881 256l-74.883-74.881 29.121-29.116L256 226.881l74.881-74.878 29.12 29.116L285.119 256l74.883 74.881z","children":"$undefined"}]]],"style":{"color":"$undefined"},"height":"1em","width":"1em","xmlns":"http://www.w3.org/2000/svg"}],["$","h1",null,{"className":"font-bold text-7xl underline decoration-grapefruit mb-5","children":"404."}],["$","p",null,{"children":"Your requested page was not found."}],["$","$L4",null,{"href":"/","className":"font-medium text-inherit","children":"Return to home →"}]]}]}],[]],"forbidden":"$undefined","unauthorized":"$undefined"}]}]]}]]}],{"children":["writeups",["$","$1","c",{"children":[null,["$","main",null,{"className":"container pt-20 pb-24","children":["$","$L2",null,{"parallelRouterKey":"children","error":"$undefined","errorStyles":"$undefined","errorScripts":"$undefined","template":["$","$L3",null,{}],"templateStyles":"$undefined","templateScripts":"$undefined","notFound":"$undefined","forbidden":"$undefined","unauthorized":"$undefined"}]}]]}],{"children":[["id","2f74ca229358e1d7ef508cfa76379d35","d"],["$","$1","c",{"children":[null,[["$","$L4",null,{"href":"/writeups","className":"text-secondary text-sm mb-10 -ml-5 block w-max","children":"← Back to writeups"}],["$","$L2",null,{"parallelRouterKey":"children","error":"$undefined","errorStyles":"$undefined","errorScripts":"$undefined","template":["$","$L3",null,{}],"templateStyles":"$undefined","templateScripts":"$undefined","notFound":"$undefined","forbidden":"$undefined","unauthorized":"$undefined"}]]]}],{"children":["__PAGE__",["$","$1","c",{"children":["$L5",null,["$","$L6",null,{"children":["$L7",["$","$L8",null,{"promise":"$@9"}]]}]]}],{},null,false]},null,false]},null,false]},null,false],["$","$1","h",{"children":[null,[["$","$La",null,{"children":"$Lb"}],["$","meta",null,{"name":"next-size-adjust","content":""}]],["$","$Lc",null,{"children":["$","div",null,{"hidden":true,"children":["$","$d",null,{"fallback":null,"children":"$Le"}]}]}]]}],false]],"m":"$undefined","G":["$f",[]],"s":false,"S":true}
b:[["$","meta","0",{"charSet":"utf-8"}],["$","meta","1",{"name":"viewport","content":"width=device-width, initial-scale=1"}]]
7:null
10:I[50674,["263","static/chunks/bc9c3264-6371ca03223855d4.js","810","static/chunks/48507feb-8452885980bba250.js","330","static/chunks/08ffe114-f47006c90e36a3eb.js","800","static/chunks/800-bd0deb6e7b7e903a.js","134","static/chunks/app/writeups/%5Bid%5D/page-54fe20cc7a9d3224.js"],"default"]
5:["$","div",null,{"children":["$","main",null,{"className":"text-pretty max-w-5xl mx-auto text-sm [&_h1]:text-5xl [&_h1]:font-semibold [&_h1]:mb-8 [&_blockquote]:text-secondary [&_blockquote]:space-y-3 [&_blockquote]:border-l-4 [&_blockquote]:border-secondary [&_blockquote]:pl-5 [&_blockquote]:mb-5 [&>_p]:my-4 [&_img]:my-5 [&_ul]:list-disc [&_ul]:pl-6 [&_ol]:list-decimal [&_ol]:pl-6 [&_img]:rounded [&_li]:my-2","children":[["$","h1","h1-0",{"children":"iCTF 2023 — Stop the model thief!"}],"\n",["$","blockquote","blockquote-0",{"children":["\n",["$","p","p-0",{"children":"To steal an ML model, an attacker often sends 'very similar versions' of the same image, which tells the attacker how the model reacts to very small changes in the input. You realized that an attacker might be trying to steal your image classification model. You're given two files - [1::model_queries.npy] a list of images that your model received as inputs and [2::user_query_indices.txt] a list of image indices (starts from zero) in [1] sent to your model by each user-id. In [2], each line contains the indices from a different user-id (e.g., the very first line is user-id 0, the second line is user-id 1). Can you help us find the attacker's user-ids (there are 20 of them)? Note:: if there were 4 attacker user-ids (e.g., 82,54,13,36), the flag will be 'ictf{13,36,54,82}' (sorted, no quotes)."}],"\n",["$","p","p-1",{"children":"We know that each attacker user-id has sent at least 5 near-duplicate attack images."}],"\n"]}],"\n",["$","p","p-0",{"children":"We're given a bunch of 32x32 \"query\" images, as well as a list of images sent by each user. Our goal is to find the 20 users who have been\nsending malicious queries."}],"\n",["$","p","p-1",{"children":"We can unzip and poke around with the images with a simple script like so:"}],"\n",["$","$L10","pre-0",{"className":"my-2","children":"import os\n\nimport numpy as np\nimport cv2\n\nqueries: np.ndarray = np.load('model_queries.npy')\n\nos.makedirs('queries', exist_ok=True)\nfor i, q in enumerate(queries):\n    cv2.imwrite(f'./queries/{i}.jpg', q)\n\nwith open('./user_query_indices.txt') as f:\n    for i, l in enumerate(f.readlines()):\n        os.makedirs(f'./users/{i}', exist_ok=True)\n\n        for id in l.split(\",\"):\n            cv2.imwrite(f'./users/{i}/{id}.jpg', queries[int(id)])","language":"py"}],"\n",["$","p","p-2",{"children":"After some clarification, the suspicious images we are meant to detect are slightly-tampered-with duplicates of other images:"}],"\n",["$","p","p-3",{"align":"center","children":["\n  ",["$","img","img-0",{"src":"https://gist.github.com/assets/60120929/d72f7b1a-b34f-40f3-a4eb-436d87250bf9"}]," ",["$","img","img-1",{"src":"https://gist.github.com/assets/60120929/6633ae65-c771-4ae6-849d-5a4f0d2d7307"}]," ",["$","img","img-2",{"src":"https://gist.github.com/assets/60120929/cdd01c46-4591-4a2f-a256-f0dae058b6cc"}]," ",["$","img","img-3",{"src":"https://gist.github.com/assets/60120929/51ee800b-06ba-4dff-ade6-5a54229096c9"}]," ",["$","img","img-4",{"src":"https://gist.github.com/assets/60120929/140d156b-d1e4-4daf-b14d-455cb56d357c"}]," ",["$","img","img-5",{"src":"https://gist.github.com/assets/60120929/93f8efee-5139-4332-967d-b226368dbbfb"}]," ",["$","img","img-6",{"src":"https://gist.github.com/assets/60120929/00cf9cdf-1315-4c30-81ba-b2d923fcf0a3"}]," ",["$","img","img-7",{"src":"https://gist.github.com/assets/60120929/8b80f3e0-ab62-446b-9dd5-41198bada2e4"}],"\n"]}],"\n",["$","p","p-4",{"children":"Because these differences are per-pixel, the brute force solution is to subtract each image from each other image and check if that sum is below\nsome threshold; if so, that pair of images is suspicious and can be labelled as such. Then, do one pass through the users and check their queries\nagainst the precomputed sus ids to determine whether that user is a malicious model-stealing agent."}],"\n","$L11","\n","$L12","\n","$L13","\n","$L14","\n","$L15","\n","$L16","\n","$L17","\n","$L18","\n","$L19"]}]}]
11:["$","p","p-5",{"children":"Here's a rough implementation of the image similarity check:"}]
12:["$","$L10","pre-1",{"className":"my-2","children":"THRESH = 20000\n\n# ...\n\ndef process_query(i: int, q: np.ndarray, queries, unique_images, sus_ids):\n    for u in unique_images:\n        diff = np.sum(cv2.absdiff(q, queries[u]))\n\n        if diff < THRESH:\n            print(i, u, diff)\n            sus_ids[i] = 1\n            sus_ids[u] = 1\n            break\n    else:\n        unique_images.append(i)","language":"py"}]
13:["$","p","p-6",{"children":["The threshold here was obtained by running a small pass of the algorithm and printing at each iteration the minimum ",["$","code","code-0",{"className":"opacity-75 bg-black/30 rounded px-1.5 py-1 text-[0.9em]","children":"diff"}]," of any pair of images.\nThe threshold value was set to an arbitrary ",["$","code","code-1",{"className":"opacity-75 bg-black/30 rounded px-1.5 py-1 text-[0.9em]","children":"2000"}]," above the highest diff \"fake\" and below the lowest diff false positive; most fakes have diffs between\n",["$","code","code-2",{"className":"opacity-75 bg-black/30 rounded px-1.5 py-1 text-[0.9em]","children":"16000 - 17000"}],", with some as low as ",["$","code","code-3",{"className":"opacity-75 bg-black/30 rounded px-1.5 py-1 text-[0.9em]","children":"12000"}],", while the most similar pair of real images had a diff of around ",["$","code","code-4",{"className":"opacity-75 bg-black/30 rounded px-1.5 py-1 text-[0.9em]","children":"30000"}],"."]}]
14:["$","$L10","pre-2",{"className":"my-2","children":"1666 2239 16581\n2307 2239 17299\n1999 1590 17126\n184 2239 16989\n1423 102 17159","language":"$undefined"}]
15:["$","h6","h6-0",{"children":"(snapshot of program output, each row showing the two ids detected as fakes and their image diff, respectively)"}]
16:["$","p","p-7",{"children":"The problem with this sledgehammer solution is that comparing images an O(n²) algorithm, where n is in the order of some 10,000 images. While each image\nis only 32x32 pixels and operating on any individual pair of images is cheap, doing that same diffing on on 10,000² = 100,000,000 images\nmight be a bit problematic."}]
1a:T424,from multiprocessing import Pool, Manager

import numpy as np
import cv2

PROCESSES = 8
THRESH = 20000


def process_query(i: int, q: np.ndarray, queries, unique_images, sus_ids):
    for u in unique_images:
        diff = np.sum(cv2.absdiff(q, queries[u]))

        if diff < THRESH:
            print(i, u, diff)
            sus_ids[i] = 1
            sus_ids[u] = 1
            break
    else:
        unique_images.append(i)


if __name__ == "__main__":
    queries: np.ndarray = np.load('model_queries.npy')

    manager = Manager()
    unique_images = manager.list()
    sus_ids = manager.dict()
    sus_users = []

    with Pool(PROCESSES) as pool:
        pool.starmap(process_query, [(i, q, queries, unique_images, sus_ids) for (i, q) in enumerate(queries)])

    print(sus_ids)

    with open('./user_query_indices.txt') as f:
        for i, l in enumerate(f.readlines()):
            suspicious = [sus_ids.get(int(s), 0) for s in l.split(",")]
            if np.sum(suspicious) >= 5:
                sus_users.append(i)

    print(sorted(sus_users))17:["$","$L10","pre-3",{"className":"my-2","children":"$1a","language":"py"}]
18:["$","p","p-8",{"children":["Unfortunately, there doesn't seem to be an obvious way around it. Loading up the task in ",["$","code","code-0",{"className":"opacity-75 bg-black/30 rounded px-1.5 py-1 text-[0.9em]","children":"multiprocessing"}]," and churning away at it on\n8 processes for about two hours, we get the flag:"]}]
19:["$","$L10","pre-4",{"className":"my-2","children":"ictf{18,27,29,32,68,106,126,158,182,189,192,232,282,330,338,370,419,438,447,465}","language":"$undefined"}]
9:{"metadata":[["$","title","0",{"children":"iCTF 2023 — Stop the model thief! | kevin.fish"}],["$","meta","1",{"name":"description","content":"To steal an ML model, an attacker often sends 'very similar versions' of the same image, which tells the attacker how the model reacts to very small changes in the input. You realized that an attacker might be trying to steal your image classification model. You're given two files - [1::model_queries.npy] a list of images that your model received as inputs and [2::user_query_indices.txt] a list of image indices (starts from zero) in [1] sent to your model by each user-id. In [2], each line contains the indices from a different user-id (e.g., the very first line is user-id 0, the second line is user-id 1). Can you help us find the attacker's user-ids (there are 20 of them)? Note:: if there were 4 attacker user-ids (e.g., 82,54,13,36), the flag will be 'ictf{13,36,54,82}' (sorted, no quotes)."}],["$","meta","2",{"property":"og:title","content":"iCTF 2023 — Stop the model thief!"}],["$","meta","3",{"property":"og:description","content":"To steal an ML model, an attacker often sends 'very similar versions' of the same image, which tells the attacker how the model reacts to very small changes in the input. You realized that an attacker might be trying to steal your image classification model. You're given two files - [1::model_queries.npy] a list of images that your model received as inputs and [2::user_query_indices.txt] a list of image indices (starts from zero) in [1] sent to your model by each user-id. In [2], each line contains the indices from a different user-id (e.g., the very first line is user-id 0, the second line is user-id 1). Can you help us find the attacker's user-ids (there are 20 of them)? Note:: if there were 4 attacker user-ids (e.g., 82,54,13,36), the flag will be 'ictf{13,36,54,82}' (sorted, no quotes)."}],["$","meta","4",{"name":"twitter:card","content":"summary"}],["$","meta","5",{"name":"twitter:title","content":"iCTF 2023 — Stop the model thief!"}],["$","meta","6",{"name":"twitter:description","content":"To steal an ML model, an attacker often sends 'very similar versions' of the same image, which tells the attacker how the model reacts to very small changes in the input. You realized that an attacker might be trying to steal your image classification model. You're given two files - [1::model_queries.npy] a list of images that your model received as inputs and [2::user_query_indices.txt] a list of image indices (starts from zero) in [1] sent to your model by each user-id. In [2], each line contains the indices from a different user-id (e.g., the very first line is user-id 0, the second line is user-id 1). Can you help us find the attacker's user-ids (there are 20 of them)? Note:: if there were 4 attacker user-ids (e.g., 82,54,13,36), the flag will be 'ictf{13,36,54,82}' (sorted, no quotes)."}]],"error":null,"digest":"$undefined"}
e:"$9:metadata"
